{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUU-Qx3bi1Rd",
        "outputId": "dd2945ab-ca6a-4116-a55a-7bd1779e42dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 784)]             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 784)               79184     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 157,684\n",
            "Trainable params: 157,684\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "0\n",
            "2\n",
            "2\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "(784, 100)\n",
            "(100,)\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "(100, 784)\n",
            "(784,)\n",
            "0.0775222\n",
            "0.0\n",
            "-0.008275762\n",
            "0.0\n",
            "Training Autoencoder1:\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 28s 13ms/step - loss: 0.0434 - accuracy: 0.0110\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0195 - accuracy: 0.0114\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0128 - accuracy: 0.0124\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0099 - accuracy: 0.0131\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0081 - accuracy: 0.0128\n",
            "0.04765585\n",
            "-0.64952797\n",
            "-0.10213827\n",
            "-0.087035276\n",
            "1875/1875 [==============================] - 5s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "(60000, 100)\n",
            "(100, 50)\n",
            "(50, 100)\n",
            "Training Autoencoder2:\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0522 - accuracy: 0.0180\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0209 - accuracy: 0.0514\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0124 - accuracy: 0.0629\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0095 - accuracy: 0.0756\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0083 - accuracy: 0.1177\n",
            "1875/1875 [==============================] - 3s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "(60000, 50)\n",
            "(50, 10)\n",
            "Training Classifier:\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 1.5046 - accuracy: 0.6324\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7734 - accuracy: 0.8389\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5815 - accuracy: 0.8611\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5021 - accuracy: 0.8707\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4599 - accuracy: 0.8759\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.4228 - accuracy: 0.8863\n",
            "[0.42278212308883667, 0.8863000273704529]\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 50)                5050      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                510       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 84,060\n",
            "Trainable params: 84,060\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "(100, 50)\n",
            "(100, 50)\n",
            "Fine tuning:\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 0.2669 - accuracy: 0.9235\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1604 - accuracy: 0.9548\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1175 - accuracy: 0.9666\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0927 - accuracy: 0.9729\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0746 - accuracy: 0.9786\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.9711\n",
            "[0.09555652737617493, 0.9710999727249146]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from keras.layers import Dense, Input\n",
        "from keras.models import Model, Sequential\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = np.reshape(x_train, newshape=(60000, 784)).astype('float32')\n",
        "x_test = np.reshape(x_test, newshape=(10000, 784)).astype('float32')\n",
        "y_train=to_categorical(y_train,num_classes=10)\n",
        "y_test=to_categorical(y_test,num_classes=10)\n",
        "x_train=x_train/255\n",
        "x_test=x_test/255\n",
        "\n",
        "\n",
        "\n",
        "input_main=Input(shape=(784,))\n",
        "h1=Dense(units=100, activation='sigmoid')(input_main)\n",
        "o1=Dense(units=784, activation='sigmoid')(h1)\n",
        "autoencoder1=Model(inputs=input_main, outputs=o1)\n",
        "autoencoder1.summary()\n",
        "autoencoder1.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(type(autoencoder1.layers[0].get_weights()))\n",
        "print(type(autoencoder1.layers[1].get_weights()))\n",
        "print(type(autoencoder1.layers[2].get_weights()))\n",
        "\n",
        "print(len(autoencoder1.layers[0].get_weights()))\n",
        "print(len(autoencoder1.layers[1].get_weights()))\n",
        "print(len(autoencoder1.layers[2].get_weights()))\n",
        "\n",
        "print(type(autoencoder1.layers[1].get_weights()[0]))\n",
        "print(type(autoencoder1.layers[1].get_weights()[1]))\n",
        "print(autoencoder1.layers[1].get_weights()[0].shape)\n",
        "print(autoencoder1.layers[1].get_weights()[1].shape)\n",
        "\n",
        "print(type(autoencoder1.layers[2].get_weights()[0]))\n",
        "print(type(autoencoder1.layers[2].get_weights()[1]))\n",
        "print(autoencoder1.layers[2].get_weights()[0].shape)\n",
        "print(autoencoder1.layers[2].get_weights()[1].shape)\n",
        "\n",
        "print(autoencoder1.layers[1].get_weights()[0][50,50])\n",
        "print(autoencoder1.layers[1].get_weights()[1][10])\n",
        "print(autoencoder1.layers[2].get_weights()[0][50,50])\n",
        "print(autoencoder1.layers[2].get_weights()[1][10])\n",
        "\n",
        "print(\"Training Autoencoder1:\")\n",
        "autoencoder1.fit(x_train,x_train,epochs=5)\n",
        "\n",
        "print(autoencoder1.layers[1].get_weights()[0][50,50])\n",
        "print(autoencoder1.layers[1].get_weights()[1][10])\n",
        "print(autoencoder1.layers[2].get_weights()[0][50,50])\n",
        "print(autoencoder1.layers[2].get_weights()[1][10])\n",
        "\n",
        "autoencoder1_hidden_output=autoencoder1.layers[1].output\n",
        "trimmed_autoencoder1=Model(inputs=input_main, outputs=autoencoder1_hidden_output)\n",
        "x_train_ae2=trimmed_autoencoder1.predict(x_train)\n",
        "x_test_ae2=trimmed_autoencoder1.predict(x_test)\n",
        "print(x_train_ae2.shape)\n",
        "\n",
        "\n",
        "inputs_ae2=Input(shape=(100,))\n",
        "h2=Dense(units=50, activation='sigmoid')(inputs_ae2)\n",
        "o2=Dense(units=100, activation='sigmoid')(h2)\n",
        "autoencoder2=Model(inputs=inputs_ae2, outputs=o2)\n",
        "autoencoder2.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
        "print(autoencoder2.layers[1].get_weights()[0].shape)\n",
        "print(autoencoder2.layers[2].get_weights()[0].shape)\n",
        "print(\"Training Autoencoder2:\")\n",
        "autoencoder2.fit(x_train_ae2, x_train_ae2, epochs=5)\n",
        "\n",
        "autoencoder2_hidden_output=autoencoder2.layers[1].output\n",
        "trimmed_autoencoder2=Model(inputs=inputs_ae2, outputs=autoencoder2_hidden_output)\n",
        "x_train_clf=trimmed_autoencoder2.predict(x_train_ae2)\n",
        "x_test_clf=trimmed_autoencoder2.predict(x_test_ae2)\n",
        "print(x_train_clf.shape)\n",
        "\n",
        "inputs_clf=Input(shape=(50,))\n",
        "f_output=Dense(units=10, activation='softmax')(inputs_clf)\n",
        "clf=Model(inputs=inputs_clf, outputs=f_output)\n",
        "clf.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(clf.layers[1].get_weights()[0].shape)\n",
        "print(\"Training Classifier:\")\n",
        "clf.fit(x_train_clf, y_train, epochs=5)\n",
        "\n",
        "\n",
        "print(clf.evaluate(x_test_clf,y_test))\n",
        "\n",
        "\n",
        "new_model=Sequential()\n",
        "new_model.add(autoencoder1.layers[0])\n",
        "new_model.add(autoencoder1.layers[1])\n",
        "new_model.add(autoencoder2.layers[1])\n",
        "new_model.add(clf.layers[-1])\n",
        "new_model.summary()\n",
        "new_model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "print(new_model.layers[1].get_weights()[0].shape)\n",
        "print(autoencoder2.layers[1].get_weights()[0].shape)\n",
        "print(\"Fine tuning:\")\n",
        "new_model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "\n",
        "print(new_model.evaluate(x_test, y_test))"
      ]
    }
  ]
}